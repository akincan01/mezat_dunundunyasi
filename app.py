from flask import Flask, request, jsonify
from flask.cli import load_dotenv
import openai
import base64
import os
import json
import re
from PIL import Image
import io

app = Flask(__name__)
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

def resize_image_for_openai(image_bytes, max_size=800, quality=60, max_file_size=1024*1024):
    """Resize image aggressively for OpenAI API - smaller size for multiple images"""
    try:
        # Open image to check dimensions
        image = Image.open(io.BytesIO(image_bytes))
        width, height = image.size
        max_dimension = max(width, height)
        
        # Check if image needs resizing (ALWAYS resize for multiple images)
        needs_resize = True  # Always resize for better OpenAI compatibility
        
        if not needs_resize:
            print(f"âœ… Image OK: {len(image_bytes)} bytes, {width}x{height}px")
            return image_bytes, False
        
        print(f"ğŸ”„ Resizing: {len(image_bytes)} bytes, {width}x{height}px -> max {max_size}px")
        
        # Calculate new size maintaining aspect ratio
        if width > height:
            new_width = min(width, max_size)
            new_height = int((height * new_width) / width)
        else:
            new_height = min(height, max_size)
            new_width = int((width * new_height) / height)
        
        # Resize image
        resized_image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)
        
        # Convert to RGB if necessary (for JPEG)
        if resized_image.mode in ("RGBA", "P"):
            resized_image = resized_image.convert("RGB")
        
        # Save to bytes
        output = io.BytesIO()
        resized_image.save(output, format="JPEG", quality=quality, optimize=True)
        resized_bytes = output.getvalue()
        
        print(f"âœ… Resized to: {len(resized_bytes)} bytes, {new_width}x{new_height}px")
        return resized_bytes, True
        
    except Exception as e:
        print(f"âŒ Error resizing image: {e}")
        return image_bytes, False

@app.route("/extract", methods=["POST"])
def extract_product_info():
    try:
        # âœ… Handle both single and multiple images (backwards compatible)
        uploaded_files = []
        
        # Try multiple images first
        if 'images' in request.files:
            uploaded_files = request.files.getlist('images')
            print(f"âœ… Found {len(uploaded_files)} images in 'images' key")
        # Fallback to single image (original format)
        elif 'image' in request.files:
            uploaded_files = [request.files['image']]
            print("âœ… Found 1 image in 'image' key")
        else:
            print("âŒ No 'images' or 'image' key found in request.files")
            print("Available keys:", list(request.files.keys()))
        
        if not uploaded_files or len(uploaded_files) == 0:
            return jsonify({"error": "HiÃ§ gÃ¶rsel yÃ¼klenmedi. En az 1 gÃ¶rsel gerekli."}), 400

        print(f"ğŸ“¸ Processing {len(uploaded_files)} images...")

        # âœ… Process ALL images for AI analysis

        # âœ… Process images for AI analysis (max 3)
        processed_images = []
        image_data_urls = []
        
        for i, image_file in enumerate(uploaded_files):  # Process ALL images
            try:
                print(f"Processing image {i+1}: {image_file.filename}")
                
                mime_type = image_file.mimetype
                print(f"MIME type: {mime_type}")
                
                # Read the original image bytes
                original_image_bytes = image_file.read()
                print(f"Original image size: {len(original_image_bytes)} bytes")

                # âœ… Supported formats
                if mime_type not in ['image/jpeg', 'image/png', 'image/webp', 'image/gif']:
                    return jsonify({"error": f"Desteklenmeyen gÃ¶rsel formatÄ±: {mime_type}"}), 400

                # âœ… Resize for OpenAI (ALWAYS resize aggressively for multiple images)
                processed_image_bytes, was_resized = resize_image_for_openai(
                    original_image_bytes, 
                    max_size=800,      # Much smaller
                    quality=60,        # Lower quality
                    max_file_size=512*1024  # 512KB limit
                )
                
                print(f"Processed image size: {len(processed_image_bytes)} bytes")
                
                # Create base64 for OpenAI (using processed/resized image)
                base64_for_openai = base64.b64encode(processed_image_bytes).decode("utf-8")
                if was_resized:
                    image_url = f"data:image/jpeg;base64,{base64_for_openai}"
                else:
                    image_url = f"data:{mime_type};base64,{base64_for_openai}"
                
                # Store original image data for Google Drive storage
                base64_original = base64.b64encode(original_image_bytes).decode("utf-8")
                
                processed_images.append({
                    "filename": image_file.filename or f"image_{i+1}",
                    "mime_type": mime_type,
                    "size_bytes": len(original_image_bytes),
                    "base64": base64_original,  # Always store original
                    "was_resized_for_ai": was_resized
                })
                
                image_data_urls.append({"type": "image_url", "image_url": {"url": image_url}})
                print(f"âœ… Successfully processed image {i+1}")
                
            except Exception as img_error:
                print(f"âŒ Error processing image {i+1}: {str(img_error)}")
                return jsonify({"error": f"Error processing image {i+1}: {str(img_error)}"}), 500

        # âœ… Enhanced prompt for multiple images
        image_count = len(uploaded_files)
        prompt = f"""
        Bu {image_count} gÃ¶rseldeki Ã¼rÃ¼nle ilgili aÅŸaÄŸÄ±daki bilgileri Ã§Ä±kar ve JSON formatÄ±nda dÃ¶ndÃ¼r.
        TÃ¼m gÃ¶rselleri analiz ederek en doÄŸru bilgiyi Ã§Ä±kar:

        - ÃœrÃ¼n AdÄ±
        - Kategori (yalnÄ±zca ÅŸu seÃ§eneklerden biri olmalÄ±: Kitap, Obje, Efemera, Plak, Tablo, Mobilya)
        - Ã–lÃ§Ã¼ veya boyut (mutlaka santimetre cinsinden belirt)
        - Marka / YayÄ±nevi / Plak Åirketi (eÄŸer varsa)
        - Model / Plak BaskÄ± Kodu / Seri No (eÄŸer varsa)
        - Tarih / DÃ¶nem (fotograftan bulunabiliyorsa, yoksa tahmin et)
        - Malzeme (objeler ve mobilyalar iÃ§in tahmin et)
        - Adet (fotoÄŸrafta birden fazla Ã¼rÃ¼n varsa adedini yaz)
        - Kondisyon (ÃœrÃ¼nÃ¼n kondisyonunu 1'den 10'a kadar puanla. KusurlarÄ± varsa belirt)
        - Etiket (Ã¶rnek: #ElvisPresley #MÃ¼zik)
        - Tarz / TÃ¼r (Ã¶rnek: pop art, mid-century, roman, ÅŸiir, caz vs.)
        - Notlar (Ã¼rÃ¼nÃ¼n tarihi, ilginÃ§ bilgi, kimin kullandÄ±ÄŸÄ± vs. kÄ±sa ve deÄŸerli notlar)
        - Sosyal Medya / Arama Motoru Etiketleri (virgÃ¼lle ayÄ±r)
        - Kitap AdÄ± / AlbÃ¼m AdÄ± / Tablo AdÄ±
        - Yazar / SanatÃ§Ä± AdÄ±

        Birden fazla gÃ¶rsel varsa, hepsini analiz et ve en kapsamlÄ± bilgiyi Ã§Ä±kar.
        Sadece TÃ¼rkÃ§e, geÃ§erli bir JSON formatÄ± dÃ¶ndÃ¼r.

        Ã–rnek format:
        {{
          "itemName": "Elvis - The Moviestar",
          "category": "Plak",
          "size": "31x31 cm",
          "brand": "RCA Records",
          "model": "APL1-2566",
          "period": "1977",
          "material": "",
          "quantity": "1",
          "condition": "8/10 - Kapakta kÃ¼Ã§Ã¼k yÄ±pranma",
          "tags": "#ElvisPresley, #MÃ¼zik",
          "style": "Rock",
          "notes": "Bu plak Elvis'in sinema kariyerine adanmÄ±ÅŸ nadir baskÄ±lardan biridir.",
          "seoKeywords": "elvis, plak, vintage, mÃ¼zik, rock",
          "title": "The Moviestar",
          "author": "Elvis Presley"
        }}
        """

        # âœ… Prepare messages with all images
        message_content = [{"type": "text", "text": prompt}]
        message_content.extend(image_data_urls)

        print(f"ğŸ¤– Sending {len(image_data_urls)} images to OpenAI...")

        # âœ… OpenAI call with multiple images
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "Bir Ã¼rÃ¼n tanÄ±mlama asistanÄ±sÄ±n. Birden fazla gÃ¶rsel verildiÄŸinde hepsini analiz et."},
                {"role": "user", "content": message_content}
            ],
            max_tokens=1500
        )

        print("âœ… OpenAI response received")

        raw = response.choices[0].message.content.strip()

        # ğŸ§¹ Remove markdown code blocks
        cleaned = re.sub(r"^```json|```$", "", raw, flags=re.MULTILINE).strip()
        
        # âœ… Parse the product data
        product_data = json.loads(cleaned)
        
        # âœ… Add image count and filenames
        product_data["imageCount"] = len(processed_images)
        product_data["imageFilenames"] = [img["filename"] for img in processed_images]
        product_data["images"] = processed_images  # Include ALL images

        return jsonify(product_data)

    except json.JSONDecodeError as e:
        print("âŒ JSON Parse Error:", str(e))
        return jsonify({"error": f"JSON formatÄ± hatasÄ±: {str(e)}"}), 500
    except Exception as e:
        print("âŒ Error:", str(e))
        return jsonify({"error": str(e)}), 500

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001, debug=True)